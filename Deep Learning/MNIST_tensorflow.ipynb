{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhOnSTvpwGnsUBYQRNA5yL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aish793/Sandbox/blob/master/Deep%20Learning/MNIST_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ytHc-LasWcB",
        "colab_type": "text"
      },
      "source": [
        "Importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSFHKMubdd8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PIH1Rrfs7yQ",
        "colab_type": "text"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3bYCp0pyYw7",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "44411c3a-5507-4c27-a21b-f16897e7b6bc"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cdee184d-ea9e-41f9-82db-8df98d166705\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-cdee184d-ea9e-41f9-82db-8df98d166705\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving datasets.py to datasets.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'datasets.py': b'import numpy as np\\n\\n\\nclass MNISTDataset:\\n    \"\"\"\\'Bare minimum\\' class to wrap MNIST numpy arrays into a dataset.\"\"\"\\n    def __init__(self, train_imgs, train_lbs, test_imgs, test_lbls, batch_size,\\n                 to01=True, shuffle=True, seed=None):\\n        \"\"\"\\n        Use seed optionally to always get the same shuffling (-> reproducible\\n        results).\\n        \"\"\"\\n        self.batch_size = batch_size\\n        self.train_data = train_imgs\\n        self.train_labels = train_lbs.astype(np.int32)\\n        self.test_data = test_imgs\\n        self.test_labels = test_lbls.astype(np.int32)\\n\\n        if to01:\\n            # int in [0, 255] -> float in [0, 1]\\n            self.train_data = self.train_data.astype(np.float32) / 255\\n            self.test_data = self.test_data.astype(np.float32) / 255\\n\\n        self.size = self.train_data.shape[0]\\n\\n        if seed:\\n            np.random.seed(seed)\\n        if shuffle:\\n            self.shuffle_train()\\n        self.shuffle = shuffle\\n        self.current_pos = 0\\n\\n    def next_batch(self):\\n        \"\"\"Either gets the next batch, or optionally shuffles and starts a\\n        new epoch.\"\"\"\\n        end_pos = self.current_pos + self.batch_size\\n        if end_pos < self.size:\\n            batch = (self.train_data[self.current_pos:end_pos],\\n                     self.train_labels[self.current_pos:end_pos])\\n            self.current_pos += self.batch_size\\n        else:\\n            # we return what\\'s left (-> possibly smaller batch!) and prepare\\n            # the start of a new epoch\\n            batch = (self.train_data[self.current_pos:self.size],\\n                     self.train_labels[self.current_pos:self.size])\\n            if self.shuffle:\\n                self.shuffle_train()\\n            self.current_pos = 0\\n            print(\"Starting new epoch...\")\\n        return batch\\n\\n    def shuffle_train(self):\\n        shuffled_inds = np.arange(self.train_data.shape[0])\\n        np.random.shuffle(shuffled_inds)\\n        self.train_data = self.train_data[shuffled_inds]\\n        self.train_labels = self.train_labels[shuffled_inds]\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Coi1b6vvyk2-",
        "colab_type": "text"
      },
      "source": [
        "Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfw24b_8s6st",
        "colab_type": "code",
        "outputId": "d1fc3c07-5adb-4613-ef19-474e059c9b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "from datasets import MNISTDataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() # train_images = (60000,28,28) train_labels = (60000,), test_images.shape = (10000,28,28)\n",
        "\n",
        "plt.imshow(train_images[467], cmap=\"Greys_r\")\n",
        "\n",
        "data = MNISTDataset(train_images.reshape([-1, 784]), train_labels, \n",
        "                    test_images.reshape([-1, 784]), test_labels,\n",
        "                    batch_size=128)    # data = datasets.MNISTDataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_VwyNTy37g",
        "colab_type": "text"
      },
      "source": [
        "Multi Layer Perceptron(MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZjfWLcuuX2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameters\n",
        "train_steps = 1000\n",
        "learning_rate = 0.1\n",
        "input_neurons = 784\n",
        "layer1_neurons = 512\n",
        "output_neurons = 10 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEZdTMe7EhP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# layer1\n",
        "W1 = tf.Variable(tf.random.uniform([input_neurons,layer1_neurons], minval=-0.1, maxval=0.1, dtype=tf.dtypes.float32))\n",
        "b1 = tf.Variable(np.zeros(layer1_neurons, dtype=np.float32))\n",
        "\n",
        "#output layer\n",
        "W2 = tf.Variable(tf.random.uniform([layer1_neurons,output_neurons], minval=-0.1, maxval=0.1, dtype=tf.dtypes.float32))\n",
        "b2 = tf.Variable(np.zeros(output_neurons, dtype=np.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvt3_jmGHwDW",
        "colab_type": "code",
        "outputId": "2e54d1fa-79dc-42ed-fbb3-9d1415acf7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "def cal_logits(x):\n",
        "  h1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1) # layer1\n",
        "  o1= tf.matmul(h1, W2) + b2 # output layer\n",
        "  return o1\n",
        "\n",
        "for step in range(train_steps):\n",
        "  img_batch, lbl_batch = data.next_batch() #img_batch = (128,784), lbl_batch = (128,)\n",
        "  with tf.GradientTape(persistent=True) as tape:#computes the gradient w.r.t input variables\n",
        "     logits = cal_logits(img_batch)\n",
        "     xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=lbl_batch))\n",
        "  grads = tape.gradient(xent, [W1, b1, W2, b2])\n",
        "\n",
        "  W1.assign_sub(learning_rate * grads[0])\n",
        "  b1.assign_sub(learning_rate * grads[1])\n",
        "\n",
        "  W2.assign_sub(learning_rate * grads[2])\n",
        "  b2.assign_sub(learning_rate * grads[3])\n",
        "\n",
        "  if not step % 100:\n",
        "      preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "      acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch),\n",
        "                             tf.float32))\n",
        "      print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.5309672355651855 Accuracy: 0.0703125\n",
            "Loss: 1.1334214210510254 Accuracy: 0.7578125\n",
            "Loss: 0.7879695892333984 Accuracy: 0.796875\n",
            "Starting new epoch...\n",
            "Loss: 0.621806263923645 Accuracy: 0.84375\n",
            "Loss: 0.4959004521369934 Accuracy: 0.8671875\n",
            "Loss: 0.4744044542312622 Accuracy: 0.8671875\n",
            "Loss: 0.35258522629737854 Accuracy: 0.8984375\n",
            "Loss: 0.3617587983608246 Accuracy: 0.8984375\n",
            "Starting new epoch...\n",
            "Loss: 0.31398069858551025 Accuracy: 0.921875\n",
            "Loss: 0.458537220954895 Accuracy: 0.8515625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6LGDykXxbmR",
        "colab_type": "text"
      },
      "source": [
        "Testing the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFQFSAYCmyq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5c9d8542-ff9a-483a-966c-a166e661e49b"
      },
      "source": [
        "test_pred_h1 = tf.nn.relu(tf.matmul(data.test_data, W1) + b1)  \n",
        "test_preds = tf.argmax(tf.matmul(test_pred_h1, W2) + b2, axis=1,\n",
        "                       output_type=tf.int32)\n",
        "test_acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, data.test_labels),\n",
        "                             tf.float64))\n",
        "\n",
        "print(\"Accuracy: {}\".format(test_acc))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP7ZxFiJaPeh",
        "colab_type": "text"
      },
      "source": [
        "Observations:\n",
        "\n",
        "Hidden layers - 1 | No of neurons in hidden layers - 512 | Activation Function - RelU, Softmax | Acc(Tr,Test) = 93.75,94.27\n",
        "\n",
        "Hidden layers - 1 | No of neurons in hidden layers - 112 | Activation Function - RelU, Softmax | Acc(Tr,Test) = 95.31,93.15\n",
        "\n",
        "\n",
        "Hidden layers - 1 | No of neurons in hidden layers - 16 | Activation Function - RelU, Softmax | Acc(Tr,Test) = 94.53,91.71\n",
        "\n",
        "\n",
        "Hidden layers - 1 | No of neurons in hidden layers - 512 | Activation Function - Tanh, Softmax | Acc(Tr,Test) = 93.75 , 85.56\n",
        "\n",
        "Hidden layers - 1 | No of neurons in hidden layers - 512 | Activation Function - Sigmoid, Softmax | Acc(Tr,Test) = 85.15, 84.49"
      ]
    }
  ]
}